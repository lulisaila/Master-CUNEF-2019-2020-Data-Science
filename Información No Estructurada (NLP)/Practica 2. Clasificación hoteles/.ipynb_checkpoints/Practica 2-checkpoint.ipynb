{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2: Clasificación\n",
    "## Autor: Lucía Saiz Lapique\n",
    "### Fecha: 18/04/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luli\\Documents\\Anaconda\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm #Para la barrita\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import nltk, re, pprint\n",
    "from nltk import tokenize # a tweet tokenizer from nltk.\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÉTODO NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lea el contenido del fichero csv en un DataFrame. Se sugiere utilizar la función pandas.read_csv. Atención a la codificación de los datos entrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('hotel.csv', encoding = 'UTF-8')\n",
    "datos = datos.sample(frac = 1).reset_index(drop = True) ## como los datos estan ordenados por valoracion, decidimos aleatorizarlos\n",
    "## para evitar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>El hotel es muy lindo; cada abitación con su p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Me encantaron las habitaciones y la apariencia...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>La verdad ha sido una experiencia única; habit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Gran Hotel; impecable sus instalaciones; el pe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Es la mejor opción para alojarte en asunción; ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  El hotel es muy lindo; cada abitación con su p...      5\n",
       "1  Me encantaron las habitaciones y la apariencia...      5\n",
       "2  La verdad ha sido una experiencia única; habit...      3\n",
       "3  Gran Hotel; impecable sus instalaciones; el pe...      5\n",
       "4  Es la mejor opción para alojarte en asunción; ...      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realice el pre-procesamiento que considere necesario. Puede utilizar funciones de la librería NLTK o spaCy, a su voluntad. Recomendamos una escritura modular del código, para poder hacer pruebas posteriormente, viendo si se obtienen mejores resultados al utilizar stop-words, al realizar una extracción de formas canónicas, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizamos con NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      El hotel es muy lindo; cada abitación con su p...\n",
      "1      Me encantaron las habitaciones y la apariencia...\n",
      "2      La verdad ha sido una experiencia única; habit...\n",
      "3      Gran Hotel; impecable sus instalaciones; el pe...\n",
      "4      Es la mejor opción para alojarte en asunción; ...\n",
      "                             ...                        \n",
      "195    Muy buena excelente; muy buena ubicación; cerc...\n",
      "196    Muy bonita experiencia la estadía en el Hotel;...\n",
      "197    Excelente atención; instalaciones; comodidad; ...\n",
      "198    Estadía súper relajada y placentera. Impecable...\n",
      "199    Seria bueno dejar tazas para el cafe al alcanz...\n",
      "Name: text, Length: 200, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# introducimos el texto en una variable para tokenizarlo\n",
    "texto = datos.text\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## funcion que me ha pasado miguel para tokenizar\n",
    "def analizador_nltk(texto):\n",
    "    vectorizador = CountVectorizer(min_df = 10, max_df = 1.0, stop_words = spanish_stopwords, max_features = max_features)\n",
    "    analyze = vectorizador.build_analyzer()\n",
    "    tokens = analyze(texto)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|█████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 973.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>El hotel es muy lindo; cada abitación con su p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[hotel, lindo, cada, abitación, proprio, estil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Me encantaron las habitaciones y la apariencia...</td>\n",
       "      <td>5</td>\n",
       "      <td>[encantaron, habitaciones, apariencia, hotel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>La verdad ha sido una experiencia única; habit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[verdad, sido, experiencia, única, habitacione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Gran Hotel; impecable sus instalaciones; el pe...</td>\n",
       "      <td>5</td>\n",
       "      <td>[gran, hotel, impecable, instalaciones, person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Es la mejor opción para alojarte en asunción; ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[mejor, opción, alojarte, asunción, buenas, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>Muy buena excelente; muy buena ubicación; cerc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[buena, excelente, buena, ubicación, cerca, ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>Muy bonita experiencia la estadía en el Hotel;...</td>\n",
       "      <td>5</td>\n",
       "      <td>[bonita, experiencia, estadía, hotel, mucha, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>Excelente atención; instalaciones; comodidad; ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[excelente, atención, instalaciones, comodidad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>Estadía súper relajada y placentera. Impecable...</td>\n",
       "      <td>5</td>\n",
       "      <td>[estadía, súper, relajada, placentera, impecab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>Seria bueno dejar tazas para el cafe al alcanz...</td>\n",
       "      <td>5</td>\n",
       "      <td>[seria, bueno, dejar, tazas, cafe, alcanze, hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "0    El hotel es muy lindo; cada abitación con su p...      5   \n",
       "1    Me encantaron las habitaciones y la apariencia...      5   \n",
       "2    La verdad ha sido una experiencia única; habit...      3   \n",
       "3    Gran Hotel; impecable sus instalaciones; el pe...      5   \n",
       "4    Es la mejor opción para alojarte en asunción; ...      5   \n",
       "..                                                 ...    ...   \n",
       "195  Muy buena excelente; muy buena ubicación; cerc...      5   \n",
       "196  Muy bonita experiencia la estadía en el Hotel;...      5   \n",
       "197  Excelente atención; instalaciones; comodidad; ...      5   \n",
       "198  Estadía súper relajada y placentera. Impecable...      5   \n",
       "199  Seria bueno dejar tazas para el cafe al alcanz...      5   \n",
       "\n",
       "                                                tokens  \n",
       "0    [hotel, lindo, cada, abitación, proprio, estil...  \n",
       "1    [encantaron, habitaciones, apariencia, hotel, ...  \n",
       "2    [verdad, sido, experiencia, única, habitacione...  \n",
       "3    [gran, hotel, impecable, instalaciones, person...  \n",
       "4    [mejor, opción, alojarte, asunción, buenas, in...  \n",
       "..                                                 ...  \n",
       "195  [buena, excelente, buena, ubicación, cerca, ce...  \n",
       "196  [bonita, experiencia, estadía, hotel, mucha, a...  \n",
       "197  [excelente, atención, instalaciones, comodidad...  \n",
       "198  [estadía, súper, relajada, placentera, impecab...  \n",
       "199  [seria, bueno, dejar, tazas, cafe, alcanze, hu...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se crea la funcion token donde se tienen en cuenta las palabras principales\n",
    "datos['tokens'] = datos['text'].progress_map(analizador_nltk)\n",
    "datos.reset_index(inplace=True)\n",
    "datos.drop('index', inplace=True, axis=1)\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Division del dataset en entrenamiento y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División en conjunto de entrenamiento y test\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(datos['tokens'], datos['label'], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas (categorías)\n",
    "# Las categorías tienen una etiqueta tipo string, pero los algoritmos de clasifiación necesitan un valor numérico\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convierta el corpus de documentos en una matriz TF-idf. Lo más cómodo es utilizar el vectorizador TfidfVectorizer, que forma parte de sklearn. ¿Tiene influencia en el resultado final el número máximo de features a utilizar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function <lambda> at 0x00000239D58043A8>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorización: consitución de matrices tf-idf a partir de los subconjuntos de entrenamiento y test\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(analyzer = lambda x: x, min_df = 1)\n",
    "Tfidf_vect.fit(datos['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x2284 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4389 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sí que influye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Llegados a este punto, realice modelos de entrenamiento al menos con algoritmos de clasificador bayesiano ingenuo y máquinas SVM. Obtenga resultados de precisión de la clasificación, así como las matrices de confusión para ambos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algoritmo - Naive Bayes\n",
    "# Se añade al clasificador el subconjunto de entrenamiento\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  72.0\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[25  3]\n",
      " [11 11]]\n"
     ]
    }
   ],
   "source": [
    "# Se generan las predicciones\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "# Y se obtiene la precisión del modelo \n",
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB, Test_Y) * 100)\n",
    "print(\"Naive Bayes Confusion Matrix:\")\n",
    "print(confusion_matrix(Test_Y, predictions_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algoritmo - SVM\n",
    "# Se añade al clasificador el subconjunto de entrenamiento\n",
    "SVM = svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto')\n",
    "SVM.fit(Train_X_Tfidf, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  68.0\n",
      "SVM Matrix:\n",
      "[[23  5]\n",
      " [11 11]]\n"
     ]
    }
   ],
   "source": [
    "# Se generan las predicciones\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# Y se obtiene la precisión del modelo \n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "print(\"SVM Matrix:\")\n",
    "print(confusion_matrix(Test_Y, predictions_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lanzamos el modelo con 1000 arboles de decision\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# entrenamos el modelo con los datos de entrenamiento\n",
    "rf.fit(Train_X_Tfidf, Train_Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se generan las predicciones\n",
    "predictions_RF = rf.predict(Test_X_Tfidf)\n",
    "predictions_RF2 = predictions_RF.round()\n",
    "predictions_RF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score ->  70.0\n",
      "RF Matrix:\n",
      "[[20  8]\n",
      " [ 7 15]]\n"
     ]
    }
   ],
   "source": [
    "# Y se obtiene la precisión del modelo \n",
    "print(\"RF Accuracy Score -> \", accuracy_score(predictions_RF2, Test_Y)*100)\n",
    "print(\"RF Matrix:\")\n",
    "print(confusion_matrix(Test_Y, predictions_RF2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÉTODO SPACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lea el contenido del fichero csv en un DataFrame. Se sugiere utilizar la función pandas.read_csv. Atención a la codificación de los datos entrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2 = pd.read_csv('hotel.csv', encoding = 'UTF-8')\n",
    "datos2 = datos2.sample(frac = 1).reset_index(drop = True) ## como los datos estan ordenados por valoracion, decidimos aleatorizarlos\n",
    "## para evitar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>El hotel es muy lindo; cada abitación con su p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[hotel, lindo, cada, abitación, proprio, estil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Me encantaron las habitaciones y la apariencia...</td>\n",
       "      <td>5</td>\n",
       "      <td>[encantaron, habitaciones, apariencia, hotel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>La verdad ha sido una experiencia única; habit...</td>\n",
       "      <td>3</td>\n",
       "      <td>[verdad, sido, experiencia, única, habitacione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Gran Hotel; impecable sus instalaciones; el pe...</td>\n",
       "      <td>5</td>\n",
       "      <td>[gran, hotel, impecable, instalaciones, person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Es la mejor opción para alojarte en asunción; ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[mejor, opción, alojarte, asunción, buenas, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  El hotel es muy lindo; cada abitación con su p...      5   \n",
       "1  Me encantaron las habitaciones y la apariencia...      5   \n",
       "2  La verdad ha sido una experiencia única; habit...      3   \n",
       "3  Gran Hotel; impecable sus instalaciones; el pe...      5   \n",
       "4  Es la mejor opción para alojarte en asunción; ...      5   \n",
       "\n",
       "                                              tokens  \n",
       "0  [hotel, lindo, cada, abitación, proprio, estil...  \n",
       "1  [encantaron, habitaciones, apariencia, hotel, ...  \n",
       "2  [verdad, sido, experiencia, única, habitacione...  \n",
       "3  [gran, hotel, impecable, instalaciones, person...  \n",
       "4  [mejor, opción, alojarte, asunción, buenas, in...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Realice el pre-procesamiento que considere necesario. Puede utilizar funciones de la librería NLTK o spaCy, a su voluntad. Recomendamos una escritura modular del código, para poder hacer pruebas posteriormente, viendo si se obtienen mejores resultados al utilizar stop-words, al realizar una extracción de formas canónicas, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizamos ahora con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías que corresponda\n",
    "# Hay que añadir los modelos que se utilicen. Previamente cargados con python -m spacy download es_core_news_md\n",
    "\n",
    "nlp_esp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizador_spacy(texto):\n",
    "    docum_analizado = nlp_esp(texto)\n",
    "    tokens = [palabra.text for palabra in docum_analizado]\n",
    "    frases_token = []\n",
    "    for word in tokens:\n",
    "        palabras = nlp_esp.vocab[word]\n",
    "        if (palabras.is_stop == False) & (palabras.is_punct == False):\n",
    "            frases_token.append(word) \n",
    "    return frases_token   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████████████████████████████████████████████████████████████| 200/200 [00:05<00:00, 35.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Seria bueno dejar tazas para el cafe al alcanz...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Seria, dejar, tazas, cafe, alcanze, huespedes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Colchon increíble. Habitación con todos los de...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Colchon, increíble, Habitación, detalles, esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Precioso hotel y excelente atencion. Muy bien ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Precioso, hotel, y, excelente, atencion, ubic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Viajo asiduamente de negocios a Asunción y sie...</td>\n",
       "      <td>5</td>\n",
       "      <td>[Viajo, asiduamente, negocios, a, Asunción, y,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hace unos días participamos de un desayuno de ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[participamos, desayuno, periodistas, y, quedé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>Siempre es un placer hospedarse en este hotel;...</td>\n",
       "      <td>5</td>\n",
       "      <td>[placer, hospedarse, hotel, atención, excelent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>Me hospede por 2 noches en este hotel; fui de ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[hospede, 2, noches, hotel, compañera, quedamo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>Excelente experiencia para los negocios o en f...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Excelente, experiencia, negocios, o, familia,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>Está ubicado en una linda zona; frente a un sh...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ubicado, linda, zona, frente, a, shopping, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>La ubicacion del hotel es muy buena ya que se ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ubicacion, hotel, mall, avenida, central, y, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "0    Seria bueno dejar tazas para el cafe al alcanz...      5   \n",
       "1    Colchon increíble. Habitación con todos los de...      5   \n",
       "2    Precioso hotel y excelente atencion. Muy bien ...      3   \n",
       "3    Viajo asiduamente de negocios a Asunción y sie...      5   \n",
       "4    Hace unos días participamos de un desayuno de ...      3   \n",
       "..                                                 ...    ...   \n",
       "195  Siempre es un placer hospedarse en este hotel;...      5   \n",
       "196  Me hospede por 2 noches en este hotel; fui de ...      3   \n",
       "197  Excelente experiencia para los negocios o en f...      3   \n",
       "198  Está ubicado en una linda zona; frente a un sh...      5   \n",
       "199  La ubicacion del hotel es muy buena ya que se ...      5   \n",
       "\n",
       "                                                tokens  \n",
       "0    [Seria, dejar, tazas, cafe, alcanze, huespedes...  \n",
       "1    [Colchon, increíble, Habitación, detalles, esp...  \n",
       "2    [Precioso, hotel, y, excelente, atencion, ubic...  \n",
       "3    [Viajo, asiduamente, negocios, a, Asunción, y,...  \n",
       "4    [participamos, desayuno, periodistas, y, quedé...  \n",
       "..                                                 ...  \n",
       "195  [placer, hospedarse, hotel, atención, excelent...  \n",
       "196  [hospede, 2, noches, hotel, compañera, quedamo...  \n",
       "197  [Excelente, experiencia, negocios, o, familia,...  \n",
       "198  [ubicado, linda, zona, frente, a, shopping, gr...  \n",
       "199  [ubicacion, hotel, mall, avenida, central, y, ...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se crea la funcion token donde se tienen en cuenta las palabras principales\n",
    "datos2['tokens'] = datos2['text'].progress_map(analizador_spacy)\n",
    "datos2.reset_index(inplace = True)\n",
    "datos2.drop('index', inplace = True, axis = 1)\n",
    "datos2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Division del dataset en entrenamiento y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División en conjunto de entrenamiento y test\n",
    "\n",
    "Train_X2, Test_X2, Train_Y2, Test_Y2 = model_selection.train_test_split(datos2['tokens'], datos2['label'], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de etiquetas (categorías)\n",
    "# Las categorías tienen una etiqueta tipo string, pero los algoritmos de clasifiación necesitan un valor numérico\n",
    "\n",
    "Encoder2 = LabelEncoder()\n",
    "Train_Y2 = Encoder2.fit_transform(Train_Y2)\n",
    "Test_Y2 = Encoder2.fit_transform(Test_Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convierta el corpus de documentos en una matriz TF-idf. Lo más cómodo es utilizar el vectorizador TfidfVectorizer, que forma parte de sklearn. ¿Tiene influencia en el resultado final el número máximo de features a utilizar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function <lambda> at 0x00000239D5937168>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorización: consitución de matrices tf-idf a partir de los subconjuntos de entrenamiento y test\n",
    "\n",
    "Tfidf_vect2 = TfidfVectorizer(analyzer = lambda x: x, min_df = 1, max_features = 5000)\n",
    "Tfidf_vect2.fit(datos2['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_Tfidf2 = Tfidf_vect2.transform(Train_X2)\n",
    "Test_X_Tfidf2 = Tfidf_vect2.transform(Test_X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Llegados a este punto, realice modelos de entrenamiento al menos con algoritmos de clasificador bayesiano ingenuo y máquinas SVM. Obtenga resultados de precisión de la clasificación, así como las matrices de confusión para ambos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algoritmo - Naive Bayes\n",
    "# Se añade al clasificador el subconjunto de entrenamiento\n",
    "Naive2 = naive_bayes.MultinomialNB()\n",
    "Naive2.fit(Train_X_Tfidf2, Train_Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  57.99999999999999\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[25  0]\n",
      " [21  4]]\n"
     ]
    }
   ],
   "source": [
    "# Se generan las predicciones\n",
    "predictions_NB2 = Naive2.predict(Test_X_Tfidf2)\n",
    "\n",
    "# Y se obtiene la precisión del modelo \n",
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB2, Test_Y2)*100)\n",
    "print(\"Naive Bayes Confusion Matrix:\")\n",
    "print(confusion_matrix(Test_Y2, predictions_NB2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algoritmo - SVM\n",
    "# Se añade al clasificador el subconjunto de entrenamiento\n",
    "SVM2 = svm.SVC(C = 1.0, kernel = 'linear', degree = 3, gamma = 'auto')\n",
    "SVM2.fit(Train_X_Tfidf2, Train_Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  62.0\n",
      "SVM Matrix:\n",
      "[[20  5]\n",
      " [14 11]]\n"
     ]
    }
   ],
   "source": [
    "# Se generan las predicciones\n",
    "predictions_SVM2 = SVM2.predict(Test_X_Tfidf2)\n",
    "\n",
    "# Y se obtiene la precisión del modelo \n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM2, Test_Y2) * 100)\n",
    "print(\"SVM Matrix:\")\n",
    "print(confusion_matrix(Test_Y2, predictions_SVM2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lanzamos el modelo con 1000 arboles de decision\n",
    "rf2 = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# entrenamos el modelo con los datos de entrenamiento\n",
    "rf2.fit(Train_X_Tfidf2, Train_Y2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se generan las predicciones\n",
    "predictions_RF3 = rf2.predict(Test_X_Tfidf2)\n",
    "predictions_RF4 = predictions_RF3.round()\n",
    "predictions_RF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score ->  60.0\n",
      "RF Matrix:\n",
      "[[16  9]\n",
      " [11 14]]\n"
     ]
    }
   ],
   "source": [
    "# Y se obtiene la precisión del modelo \n",
    "print(\"RF Accuracy Score -> \", accuracy_score(predictions_RF4, Test_Y2)*100)\n",
    "print(\"RF Matrix:\")\n",
    "print(confusion_matrix(Test_Y2, predictions_RF4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARATIVA FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  72.0\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[25  3]\n",
      " [11 11]]\n",
      "SVM Accuracy Score ->  68.0\n",
      "SVM Matrix:\n",
      "[[23  5]\n",
      " [11 11]]\n",
      "RF Accuracy Score ->  70.0\n",
      "RF Matrix:\n",
      "[[20  8]\n",
      " [ 7 15]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB, Test_Y)*100)\n",
    "print(\"Naive Bayes Confusion Matrix:\")\n",
    "print(confusion_matrix(Test_Y, predictions_NB))\n",
    "\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, Test_Y) * 100)\n",
    "print(\"SVM Matrix:\")\n",
    "print(confusion_matrix(Test_Y, predictions_SVM))\n",
    "\n",
    "print(\"RF Accuracy Score -> \", accuracy_score(predictions_RF2, Test_Y)*100)\n",
    "print(\"RF Matrix:\")\n",
    "print(confusion_matrix(Test_Y, predictions_RF2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  57.99999999999999\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[25  0]\n",
      " [21  4]]\n",
      "SVM Accuracy Score ->  62.0\n",
      "SVM Matrix:\n",
      "[[20  5]\n",
      " [14 11]]\n",
      "RF Accuracy Score ->  60.0\n",
      "RF Matrix:\n",
      "[[16  9]\n",
      " [11 14]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB2, Test_Y2)*100)\n",
    "print(\"Naive Bayes Confusion Matrix:\")\n",
    "print(confusion_matrix(Test_Y2, predictions_NB2))\n",
    "\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM2, Test_Y2) * 100)\n",
    "print(\"SVM Matrix:\")\n",
    "print(confusion_matrix(Test_Y2, predictions_SVM2))\n",
    "\n",
    "print(\"RF Accuracy Score -> \", accuracy_score(predictions_RF4, Test_Y2)*100)\n",
    "print(\"RF Matrix:\")\n",
    "print(confusion_matrix(Test_Y2, predictions_RF4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Comente los resultados obtenidos. ¿Qué factores influyen? ¿Los resultados obtenidos son los esperados inicialmente? ¿A qué se deben estos resultados? Piense en la calidad del conjunto de datos con los que está trabajando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¿Qué factores influyen?__\n",
    "\n",
    "* El tamaño de la muestra de test (si se aumenta esta muestra, mejora el accuracy)\n",
    "* Poner semilla o no\n",
    "* La cantidad de datos que hay, ya que, al ser la base de datos tan pequeña, los resultados de la precisión de predicción de cada modelo van cambiando.\n",
    "* Que los datos estén ordenados por calificación o no (al estar ordenados, se genera overfitting; por ello, al principio se decide aleatorizar el orden en el que estén)\n",
    "* Con cada iteración, cambian los resultados\n",
    "\n",
    "__¿Los resultados obtenidos son los esperados inicialmente?__\n",
    "\n",
    "Los resultados obtenidos no son los esperados, en primer lugar porque se esperaba que los reusltados de spaCy fuesen mejores que con el método de NLTK, y no ha sido así. El accuracy en todos los métodos aplicados es mejor para los tres modelos a través de NLTK que de spaCy. En los tres casos de spaCy es bastante más bajo, en alguna de las iteraciones generadas incluso no es capaz de llegar a un 60% en ninguno de los modelos.\n",
    "\n",
    "En cuanto a la selección del mejor método, se han utilizado el modelo Bayesiano, un Support Vector Machine y un Random Forest. Tras ejecutar los tres modelos para cada método, hemos realizado una comparativa de los tres modelos con cada método, comparando el accuracy y la matriz de confusión de cada uno. Analizando los resultados predictivos de los tres, para ambos métodos, el modelo que devuelve el valor más alto en accuracy y mejor matriz es el modelo Bayesiano para el método de NLTK, y el Support Vector Machine para spaCy. \n",
    "\n",
    "Sin embargo, estos datos no resultan ser muy de fiar, ya que con cada nuevo intento de ejecución del notebook, salen resultados distintos para cada modelo y cada método. \n",
    "\n",
    "__¿A qué se deben estos resultados?__\n",
    "\n",
    "Los resultados obtenidos y los problemas que han surgido (que la precisión vaya cambiando con cada iteración, que sea muy baja, etc.), se debe probablemente a que la base de datos con la que estamos trabajando es muy pequeña y, por tanto, no tiene registros suficientes para generar un modelo capacitado para predecir lo que necesitamos. Para mejorarlo, habría que ampliar la base de datos y que la muestra de train y test sean mayores. \n",
    "\n",
    "Otra cosa que se tuvo que alterar fue el orden de los registros, pues nos dimos cuenta de que estaban ordenados por la nota del label, con lo cual se generaba cierto overfitting. Aunque desordenando los datos el resultado de la precisión de predicción es menor, ahora es más fiable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
